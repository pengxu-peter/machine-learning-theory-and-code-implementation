
$\sum_{i=0}^n i^2 = \frac{(n^2+n)(2n+1)}{6}$


$$\sum_{i=0}^n i^2 = \frac{(n^2+n)(2n+1)}{6}$$


$\alpha$

$\beta$

$\omega$

$\Gamma$


$$
L =  \underbrace{ \frac{1}{N} \sum_i L_i }_\text{data loss} +  
 \underbrace{ \lambda R(W) }_\text{regularization loss} 
$$


$$ 
L =  \underbrace{ \frac{1}{N} \sum_i L_i }\_\text{data loss} +  
 \underbrace{ \lambda R(W) }\_\text{regularization loss} 
$$


ax^{2} + by^{2} + c = 0


![](http://latex.codecogs.com/gif.latex?%5Csigma%3D%5Csqrt%7B%5Cfrac%7B1%7D%7Bn%7D%7B%5Csum_%7Bk%3D1%7D%5En%28x_i-%5Cbar%7Bx%7D%29%5E2%7D%7D)

\sigma=\sqrt{\frac{1}{n}{\sum_{k=1}^n(x_i-\bar{x})^2}}



<script type="text/javascript" 
        src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> 
</script>

<script type="text/x-mathjax-config"> 
        MathJax.Hub.Config({ 
            tex2jax: {
                inlineMath: [['$','$'], ['\(','\)']]
            }
        });
</script>
